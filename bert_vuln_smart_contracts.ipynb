{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BERT for Vulnerable Smart Contracts Detection\n","This notebook uses CodeBERT to classify smart contracts as vulnerable or secure.\n","It loads a pre-trained model and performs inference on a test dataset.\n","Dependencies: transformers, torch, pandas, sklearn, tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel\n","from torch import nn\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL_NAME = \"microsoft/codebert-base\"\n","MODEL_PATH = \"codebert_contract_vuln_classifier.pt\"\n","TEST_CSV = \"full_contracts_dataset_with_source.csv\"  # Or your new test set\n","MAX_LEN = 256\n","BATCH_SIZE = 4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Prepare test data\n","df = pd.read_csv(TEST_CSV)\n","df = df[[\"source_code\", \"label\"]].dropna()\n","df = df[df[\"source_code\"].str.len() > 0]\n","print(f\"Loaded {len(df)} samples for testing.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ContractDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.texts = df[\"source_code\"].tolist()\n","        self.labels = df[\"label\"].tolist()\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        code = str(self.texts[idx])[:5000]\n","        enc = self.tokenizer(\n","            code,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\",\n","        )\n","        input_ids = enc[\"input_ids\"].squeeze(0)\n","        attn_mask = enc[\"attention_mask\"].squeeze(0)\n","        label = torch.tensor(self.labels[idx], dtype=torch.float)\n","        return input_ids, attn_mask, label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","test_ds = ContractDataset(df, tokenizer, MAX_LEN)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define model (must match your train script)\n","class CodeBERTClassifier(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.backbone = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc = nn.Linear(self.backbone.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attn_mask):\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attn_mask)\n","        cls_rep = outputs.last_hidden_state[:, 0, :]\n","        x = self.dropout(cls_rep)\n","        logits = self.fc(x)\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load model weights\n","model = CodeBERTClassifier(MODEL_NAME).to(DEVICE)\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Inference\n","preds, trues = [], []\n","with torch.no_grad():\n","    for input_ids, attn_mask, labels in tqdm(test_loader):\n","        input_ids, attn_mask = input_ids.to(DEVICE), attn_mask.to(DEVICE)\n","        logits = model(input_ids, attn_mask).squeeze(-1)\n","        probs = torch.sigmoid(logits).cpu().numpy()\n","        preds.extend((probs > 0.5).astype(int))\n","        trues.extend(labels.numpy())\n","print(classification_report(trues, preds, digits=4))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}